You will receive a long mixed-format context (emails, code, JSON, and a tiny table). Without quoting it back, produce 5 concise bullet insights and 3 open questions. Context: [EMAIL] From: A <> Subject: latency spikes... [SNIPPET] def f(x): return x*x # todo: perf… [JSON] {"feature":"rollout","pct":37,"notes":["gradual","weekend freeze"]} [TABLE] |svc|p95|err|; api|420ms|0.31%|; auth|610ms|0.02%|; db|190ms|0.04%|; [LOG] WARN retry exhausted id=9f3a
Given this pseudo-HTML with broken tags and duplicated sections, extract a clean outline (H1–H3) and list missing alt texts: <div><h1>Release Notes<h2>Fixes</h3>—null pointer on save<h2>Changes</h2><p><img src="a.png"></p><h3>Deprecations</h3><p>…</div><div><h1>Release Notes</h1>…
Read the multilingual snippet (EN/ES/FR) and write a single English summary (50–80 words), preserving key numbers and names. Texto: “El comité publicó 3 informes; la cifra clave fue 4.7%.” Texte: “La priorité est la qualité des données.” English: “Vendors missed two milestones but met the security bar.”
You’re given a semi-structured changelog blob. Normalize into semver categories (Added/Changed/Fixed/Removed) and output JSON only. Blob: [ADDED] flag: “strict_mode”; [FIXED] NPE in parser; [CHANGED] default timeout 45s→60s; [REMOVED] legacy endpoint v0; [ADDED] CLI option “–dryrun”.
From this long paragraph with units, dates, and names, produce a 3-row summary table: {who, when, claim}. Text: On March 2, 2024, Alvarez said throughput hit 12k rps; on Apr 19, Chen revised it to 9k under TLS; by July 7, ops reported 10–11k with caching.
Here is a noisy product spec followed by unrelated chatter. Ignore the chatter and extract only acceptance criteria as Gherkin. Spec: “User uploads CSV, schema inferred, errors shown inline, retry allowed.” Chatter: “Lunch at 1? Bring the blue cables. Also the cat stepped on the keyboard.”
Given this YAML (possibly inconsistent), identify contradictions and propose 3 clarifying questions. YAML: env: prod; rate_limit: 50 rps; burst: 500; notes: “unlimited for internal IPs”; policy: “no exceptions”.
Summarize the following academic abstract into: problem, method, results, limitations, next steps (bulleted). Include 1 caveat about dataset shift. Abstract: Transformer-based retrieval augmented encoders… (assume typical content and write generic but plausible bullets).
You’re given a short RAG transcript with citations and tool calls; output only the final answer plus two alternative phrasings. Transcript: [search] “latency p95 vs p99” → doc A; [read] A §3 says p99 is 4× p95 in heavy-tail; [reason] heavy-tail implies backlog sensitivity…
Convert this messy CSV header row into a cleaned schema (name:type:constraints) and propose 5 validation rules. Header: “id ,  user-id, created at , Amount($),  status ,   STATUS”.
Given the following Base64-like noise and a real message embedded in brackets, recover only the bracketed message and rewrite it politely: aqwsZ==[Please reschedule for next Tuesday, anytime after 2pm.]xy1==
Turn the mixed list into MoSCoW prioritization with one-sentence rationale for each: “Add dark mode”, “Fix intermittent login”, “Analytics: funnels”, “Rewrite billing”, “Keyboard shortcuts”, “Accessibility fixes”, “Optional email verification”.
From this partial API doc (GET/PUT/DELETE endpoints) derive a risk register with 6 entries (threat, impact, likelihood, mitigation). Doc: GET /tokens (query: user_id), PUT /users/{id} (body: role), DELETE /logs (scope).
You’ll see a code diff chunk then a commit message. Identify 3 possible regressions and 3 missing tests. Diff: - parse(str)->int; + parse(str)->int|None; added None path only in one caller; Commit: “tighter parsing”.
Here’s a compact LaTeX-ish math note: “Assume p≈0.2, n=50; using normal approx for binomial, mean=10, var=8.” Explain in plain English what that implies for outcomes, in 2–3 bullets.
Parse the semi-structured meeting note into actions grouped by owner with due dates (infer reasonable dates relative to ‘next Friday’). Note: “Sam: migrate S3 bucket once QA signs off; Priya: draft DPIA; All: decide on feature flags before launch.”
Given a short policy excerpt with three rules and two exceptions, write a user-friendly explainer and a decision flow in ASCII. Policy: “External sharing off; exception: legal; exception: exec sponsor; Internal sharing allowed.”
You’ll get a tiny JSON config then a log line; diagnose most likely cause and propose two quick checks. JSON: {"retry":3,"timeout_ms":3000,"endpoint":"https://service"} Log: “context deadline exceeded after 3.01s”.
Read the following three-paragraph customer email and produce (a) a 1-sentence empathy opener, (b) a concrete fix timeline, (c) one follow-up question. Email mentions intermittent timeouts and duplicate charges.
Normalize this markdown list into a table with columns {rule, why it matters, common mistake}, 6 rows minimum. List: strong passwords, passphrases, phishing suspicion, updates, 2FA, backups, device lock, wifi hygiene.
Take the following changelog fragments (some repeated, some conflicting) and output a deduplicated, chronologically ordered list with dates: [2022-03] “added retry”, [2023-01] “removed retry”, [2022-09] “tuned retry”.
You’ll get an excerpt of a failed build log with ANSI escape codes and noise. Parse out the 3 real errors and guess likely root cause. Log: \x1b[31mError: cannot import pkg\x1b[0m, \x1b[33mWarning:…
Given this JSON array with inconsistent field names, normalize to a schema: id, name, role. Data: [{"id":1,"user":"Sam","position":"dev"},{"user_id":2,"name":"Lee","role":"qa"}].
Here is a noisy excerpt of pseudo-XML: <item><id>7</id><title>alpha<title><cost currency="USD">19</cost></item><item><title>beta</title></item>. Fix the structure and list missing fields.
You see a short poem written with typos and odd casing. Rewrite it in clean English, keeping rhyme. Text: “thE sun rizE ovur the shor, birds cry nO moR…”
Given this log sequence with timestamps out of order, sort them and output the last event only. Logs: [09:02:11 START] … [09:01:58 RETRY] … [09:02:33 DONE].
Convert this Markdown with broken bullets into HTML. Input: - item one – still item one — * subitem — - item two — note.
You’re given a half English, half German sentence: “The server antwortete mit Fehler 502 während deploy.” Translate into fluent English while keeping the error code.
From this recipe fragment, extract only ingredients as JSON array. Input: “2 eggs, beat; 1 cup flour; Step1: mix. Step2: bake.”
Take this CSV row with missing commas and fix it. Input: “123 John Smith janesmith@example.com 42”. Expected columns: id, first, last, email, age.
Given an Apache config snippet, find 2 security misconfigs. Config: <Directory /var/www/> Options Indexes FollowSymLinks AllowOverride None Require all granted </Directory>.
Summarize this long Slack thread into 2 bullet points: @Sam: we need to roll back; @Lee: already deployed; @Priya: checking logs; @Sam: DB latency?; @Ops: metrics steady.
Given a piece of math with mixed notation, clean it up. Text: P(X>=k) ~= 1-(1-p)^n; but also p = 0.4, n=12 → expectation ~5.
Reformat this unstructured todo list into JSON with keys {task, priority}. Text: “buy milk!! urgent, finish report high, clean desk low”.
You’re given a half-finished Python dict and a description. Complete it. Dict: {“name”:“proj”, “version”:1, “deps”:[“a”, ]} Desc: add dep “b”, set status=active.
Extract 3 key phrases from this badly formatted email: “hello---please resend contract ,,, timeline uncertain ;;; need clarity.”
Translate this combined text with mixed French/English to English only: “le serveur est down since yesterday, pas encore de fix.”
Given this malformed JSON log line, fix it. Input: {"time":"2023-01-01T12:00:00Z,"msg":"start","ok":true}.
From this text blob, extract only capitalized acronyms. Blob: “The new API uses JWT, SSO, and TLS, but not FTP or SMTP anymore.”
Take this 2-column ASCII table and output CSV. Table: | id | name |; |1|Ann|; |2|Bob|; |3|C.J.| 
Given this systemd status output, summarize service state. Output: ● nginx.service - loaded active running (since Mon 2024-02-01).
You’ll see a set of CLI commands with typos. Fix and normalize them. Input: “gti status, gti cmmit -m hi, gti push origin main”.
Extract structured data {product, price, currency} from text: “Offer: WidgetX – 19.99 USD; GadgetZ – €25,00”.
Given the pseudo-SQL: SELECT id name email FROM users WHERE status=“active. Fix syntax and reformat.
Take this nested bullet list and flatten it. Input: - A - B - B1 - B2 - C. Output: [A,B,B1,B2,C].
Given this snippet of HTML with duplicate IDs, list them. HTML: <div id="x"></div><span id="y"></span><div id="x"></div>.
From the noisy time zone list, pick only valid IANA zones. Text: PST, GMT+25, Europe/London, Mars/Colony, America/New_York.
Rephrase this messy requirement into clear acceptance criteria: “When user enters email, if ok show green, if not ok show red, must be fast.”
Parse this path-like string into components: “/users/123/orders/456?status=paid”. Expected keys: resource, id, subresource, sub_id, query.
Here’s a broken CSV with mixed delimiters. Input: “id|name,age;1|Bob,32;2|Sue,29”. Output normalized CSV.